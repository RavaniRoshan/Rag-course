<!DOCTYPE html>

<html lang="en"><head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Academic RAG Journal - Module 02: Chunking Strategies</title>
<!-- Fonts -->
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Newsreader:ital,opsz,wght@0,6..72,200..800;1,6..72,200..800&amp;family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&amp;family=Geist+Mono:wght@100..900&amp;family=JetBrains+Mono:wght@100..800&amp;display=swap" rel="stylesheet"/>
<link href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:wght,FILL@100..700,0..1&amp;display=swap" rel="stylesheet"/>
<!-- Tailwind CSS -->
<script src="https://cdn.tailwindcss.com?plugins=forms,container-queries,typography"></script>
<!-- Theme Config -->
<script id="tailwind-config">
        tailwind.config = {
            darkMode: "class",
            theme: {
                extend: {
                    colors: {
                        "primary": "#b80f12",
                        "ink": "#2C2420",
                        "paper": "#F9F7F1",
                        "parchment": "#EBE6DA",
                        "graphite": "#8A817C",
                        "faded": "#D8D1C4",
                        "library-green": "#4A5D44",
                    },
                    fontFamily: {
                        "display": ["Newsreader", "serif"],
                        "serif": ["Lora", "serif"],
                        "mono": ["Geist Mono", "monospace"],
                        "code": ["JetBrains Mono", "monospace"],
                    },
                    borderRadius: {
                        "DEFAULT": "0.125rem",
                        "lg": "0.25rem",
                        "xl": "0.5rem",
                        "full": "0.5rem"
                    },
                    backgroundImage: {
                        'grain': "url('data:image/svg+xml,%3Csvg viewBox=%220 0 200 200%22 xmlns=%22http://www.w3.org/2000/svg%22%3E%3Cfilter id=%22noiseFilter%22%3E%3CfeTurbulence type=%22fractalNoise%22 baseFrequency=%220.65%22 numOctaves=%223%22 stitchTiles=%22stitch%22/%3E%3C/filter%3E%3Crect width=%22100%25%22 height=%22100%25%22 filter=%22url(%23noiseFilter)%22 opacity=%220.05%22/%3E%3C/svg%3E')",
                    }
                },
            },
        }
    </script>
<style>
        /* Custom scrollbar for a cleaner look */
        ::-webkit-scrollbar {
            width: 6px;
        }
        ::-webkit-scrollbar-track {
            background: #F9F7F1;
        }
        ::-webkit-scrollbar-thumb {
            background: #D8D1C4;
        }
        ::-webkit-scrollbar-thumb:hover {
            background: #8A817C;
        }

        /* Hide scrollbar for clean UI but allow scroll */
        .no-scrollbar::-webkit-scrollbar {
            display: none;
        }
        .no-scrollbar {
            -ms-overflow-style: none;
            scrollbar-width: none;
        }

        /* Typography overrides */
        .prose-academic p {
            margin-top: 1.5em;
            margin-bottom: 1.5em;
            line-height: 1.8;
            font-family: 'Lora', serif;
            font-size: 19px;
            color: #2C2420;
        }
        .prose-academic h2 {
            font-family: 'Newsreader', serif;
            font-weight: 600;
            color: #2C2420;
            margin-top: 2em;
            font-size: 32px;
            letter-spacing: -0.01em;
        }
        .prose-academic h3 {
            font-family: 'Newsreader', serif;
            font-weight: 600;
            color: #2C2420;
            margin-top: 1.5em;
            font-size: 24px;
        }

        /* Sepia Code Theme */
        .token.comment { color: #8A817C; font-style: italic; }
        .token.function { color: #9E2A2B; }
        .token.keyword { color: #b80f12; font-weight: bold; }
        .token.string { color: #4A5D44; }
        .token.number { color: #b80f12; }
        
        /* Marginalia hover effect */
        .marginalia-item {
            transition: transform 0.2s ease;
        }
        .marginalia-item:hover {
            transform: translateX(-4px);
        }
        
        /* Mermaid diagram styling */
        .mermaid-diagram {
            background: white;
            border: 1px solid #D8D1C4;
            border-radius: 4px;
            padding: 16px;
            margin: 20px 0;
        }
    </style>
</head>
<body class="bg-paper text-ink antialiased selection:bg-primary/20 selection:text-ink min-h-screen flex flex-col font-serif relative">
<!-- Grain Texture Overlay -->
<div class="fixed inset-0 pointer-events-none z-50 bg-grain mix-blend-multiply opacity-40"></div>
<!-- Top Navigation (Minimal) -->
<header class="sticky top-0 z-40 w-full border-b border-faded bg-paper/95 backdrop-blur-sm h-14 flex items-center justify-between px-6 lg:px-10">
<div class="flex items-center gap-4">
<a class="flex items-center gap-2 text-ink hover:text-primary transition-colors group" href="index.html">
<span class="material-symbols-outlined text-[20px] group-hover:-translate-x-1 transition-transform">arrow_back</span>
<span class="font-display font-medium text-lg tracking-tight">Syllabus</span>
</a>
<div class="h-4 w-px bg-faded mx-2"></div>
<span class="font-mono text-xs uppercase tracking-wider text-graphite">Module 02</span>
</div>
<div class="flex items-center gap-6">
<div class="hidden md:flex items-center gap-2 text-graphite text-xs font-mono">
<span class="material-symbols-outlined text-[16px]">schedule</span>
<span id="reading-time">40 min read</span>
</div>
<div class="flex gap-3">
<button id="search-btn" aria-label="Search" class="flex items-center justify-center size-8 rounded hover:bg-parchment transition-colors text-ink">
<span class="material-symbols-outlined text-[20px]">search</span>
</button>
<button aria-label="Settings" class="flex items-center justify-center size-8 rounded hover:bg-parchment transition-colors text-ink">
<span class="material-symbols-outlined text-[20px]">text_fields</span>
</button>
</div>
</div>
</header>
<!-- Main Content Layout -->
<main class="flex-1 flex justify-center w-full relative">
<div class="w-full max-w-[1440px] flex flex-row">
<!-- Left Rail: Table of Contents -->
<aside class="hidden lg:flex w-[240px] flex-col sticky top-14 h-[calc(100vh-3.5rem)] border-r border-faded overflow-y-auto pt-12 pb-10 pl-10 pr-6">
<nav class="flex flex-col gap-8">
<div>
<h4 class="font-mono text-xs uppercase tracking-widest text-graphite mb-4">Contents</h4>
<ul class="flex flex-col gap-3 font-mono text-[13px] leading-relaxed">
<li>
<a class="text-ink hover:text-primary transition-colors flex items-start gap-2 group" href="#introduction">
<span class="text-primary font-medium opacity-0 group-hover:opacity-100 transition-opacity absolute -left-4">→</span>
                                    Introduction
                                </a>
</li>
<li>
<a class="text-ink hover:text-primary transition-colors flex items-start gap-2 group" href="#chunking-algorithms">
<span class="text-primary font-medium opacity-0 group-hover:opacity-100 transition-opacity absolute -left-4">→</span>
                                    Chunking Algorithms
                                </a>
</li>
<li>
<a class="text-ink hover:text-primary transition-colors flex items-start gap-2 group" href="#semantic-chunking">
<span class="text-primary font-medium opacity-0 group-hover:opacity-100 transition-opacity absolute -left-4">→</span>
                                    Semantic Chunking
                                </a>
</li>
<li>
<a class="text-ink hover:text-primary transition-colors flex items-start gap-2 group" href="#recursive-splitting">
<span class="text-primary font-medium opacity-0 group-hover:opacity-100 transition-opacity absolute -left-4">→</span>
                                    Recursive Splitting
                                </a>
</li>
<li>
<a class="text-ink hover:text-primary transition-colors flex items-start gap-2 group" href="#context-aware-segmentation">
<span class="text-primary font-medium opacity-0 group-hover:opacity-100 transition-opacity absolute -left-4">→</span>
                                    Context-Aware Segmentation
                                </a>
</li>
</ul>
</div>
<div class="mt-auto pt-8 border-t border-faded">
<div class="flex flex-col gap-2">
<span class="font-mono text-[11px] uppercase tracking-widest text-graphite">Progress</span>
<div class="w-full bg-parchment h-1 rounded-full overflow-hidden">
<div class="bg-primary h-full w-[35%]"></div>
</div>
<span class="font-mono text-xs text-ink text-right">35%</span>
</div>
</div>
</nav>
</aside>
<!-- Center Stage: The Reader -->
<article class="flex-1 max-w-[720px] mx-auto pt-16 pb-32 px-6 md:px-12 min-h-screen">
<!-- Module Header -->
<header class="mb-16 border-b border-faded pb-12">
<div class="flex items-center gap-3 mb-6">
<span class="font-mono text-sm font-medium text-primary px-2 py-1 bg-primary/10 rounded">Module 02</span>
<span class="font-mono text-sm text-graphite">Advanced RAG Architectures</span>
</div>
<h1 class="font-display text-[48px] md:text-[56px] leading-[1.1] font-semibold text-ink tracking-tight mb-6">
                        Chunking Strategies
                    </h1>
<p class="font-serif text-xl text-ink/80 leading-relaxed max-w-[90%]">
                        Moving beyond fixed-size windows: semantic chunking, recursive splitting, and context-aware document segmentation.
                    </p>
</header>
<!-- Content Body -->
<div class="prose-academic">
<h2 id="introduction">Introduction to Chunking Strategies</h2>
<p>
Document chunking is a critical preprocessing step in Retrieval-Augmented Generation (RAG) systems. The way we divide documents into chunks significantly impacts both retrieval accuracy and the quality of generated responses. Traditional approaches rely on fixed-size windows, but modern systems employ more sophisticated strategies that preserve semantic coherence and contextual relationships.
</p>

<p>
The fundamental challenge in chunking is finding the optimal balance between:
</p>
<ul class="list-disc pl-6 my-6">
<li><strong>Granularity</strong>: Chunks must be detailed enough to contain relevant information</li>
<li><strong>Coherence</strong>: Chunks should preserve logical relationships and context</li>
<li><strong>Efficiency</strong>: Processing and retrieval should remain computationally feasible</li>
</ul>

<h2 id="chunking-algorithms">Traditional Chunking Algorithms</h2>
<h3>Fixed-Size Chunking</h3>
<p>
The simplest approach involves dividing documents into equal-sized chunks based on character count, token count, or line count. While computationally efficient, this method often breaks semantic boundaries and can separate related information.
</p>

<div class="not-prose my-12 border border-faded bg-parchment rounded-sm overflow-hidden">
<div class="flex items-center justify-between px-4 py-2 border-b border-faded bg-[#e6dfd1]">
<span class="font-mono text-xs text-ink">fixed_chunking.py</span>
<div class="flex gap-2">
<span class="text-[10px] font-mono text-graphite uppercase">Python</span>
<button class="text-graphite hover:text-primary transition-colors" onclick="copyCode(this)">
<span class="material-symbols-outlined text-[16px]">content_copy</span>
</button>
</div>
</div>
<div class="p-5 overflow-x-auto">
<pre class="font-code text-[13px] leading-6"><code class="language-python"><span class="token keyword">def</span> <span class="token function">fixed_size_chunking</span><span class="token punctuation">(</span>text<span class="token punctuation">:</span> str, chunk_size<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">512</span>, overlap<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">50</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>str<span class="token punctuation">]</span>:
    <span class="token triple-quoted-string string">"""
    Divide text into fixed-size chunks with optional overlap
    """</span>
    chunks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    start <span class="token operator">=</span> <span class="token number">0</span>
    
    <span class="token keyword">while</span> start <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span>:
        end <span class="token operator">=</span> start <span class="token operator">+</span> chunk_size
        chunk <span class="token operator">=</span> text<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span>
        chunks<span class="token punctuation">.</span>append<span class="token punctuation">(</span>chunk<span class="token punctuation">)</span>
        
        <span class="token comment"># Move start by chunk_size minus overlap</span>
        start <span class="token operator">+=</span> chunk_size <span class="token operator">-</span> overlap
        
        <span class="token comment"># Handle the last chunk which might be smaller</span>
        <span class="token keyword">if</span> start <span class="token operator">+</span> chunk_size <span class="token operator">></span> <span class="token builtin">len</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span>:
            <span class="token keyword">break</span>
    
    <span class="token keyword">return</span> chunks</code></pre>
</div>
</div>

<h3>Sentence-Boundary Chunking</h3>
<p>
This approach respects sentence boundaries when creating chunks, which preserves more semantic coherence than fixed-size chunking. However, it can still result in chunks of highly variable sizes.
</p>

<div class="not-prose my-12 border border-faded bg-parchment rounded-sm overflow-hidden">
<div class="flex items-center justify-between px-4 py-2 border-b border-faded bg-[#e6dfd1]">
<span class="font-mono text-xs text-ink">sentence_chunking.py</span>
<div class="flex gap-2">
<span class="text-[10px] font-mono text-graphite uppercase">Python</span>
<button class="text-graphite hover:text-primary transition-colors" onclick="copyCode(this)">
<span class="material-symbols-outlined text-[16px]">content_copy</span>
</button>
</div>
</div>
<div class="p-5 overflow-x-auto">
<pre class="font-code text-[13px] leading-6"><code class="language-python"><span class="token keyword">import</span> re
<span class="token keyword">from</span> typing <span class="token keyword">import</span> List

<span class="token keyword">def</span> <span class="token function">sentence_boundary_chunking</span><span class="token punctuation">(</span>text<span class="token punctuation">:</span> str, max_chunk_size<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">512</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>str<span class="token punctuation">]</span>:
    <span class="token triple-quoted-string string">"""
    Chunk text by sentence boundaries while respecting max chunk size
    """</span>
    <span class="token comment"># Split text into sentences</span>
    sentences <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span>r<span class="token string">'(?&lt;!\\)([.!?] | [.!?]$)'</span>, text<span class="token punctuation">)</span>
    
    chunks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    current_chunk <span class="token operator">=</span> <span class="token string">""</span>
    
    <span class="token keyword">for</span> sentence <span class="token keyword">in</span> sentences:
        <span class="token comment"># Add sentence separator back</span>
        sentence <span class="token operator">=</span> sentence<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> sentence<span class="token punctuation">:</span>
            sentence <span class="token operator">+=</span> <span class="token string">" "</span>
        
        <span class="token comment"># Check if adding this sentence would exceed the limit</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>current_chunk<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span> <span class="token operator">&lt;=</span> max_chunk_size:
            current_chunk <span class="token operator">+=</span> sentence
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment"># If current chunk is not empty, save it and start a new one</span>
            <span class="token keyword">if</span> current_chunk<span class="token punctuation">:</span>
                chunks<span class="token punctuation">.</span>append<span class="token punctuation">(</span>current_chunk<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            current_chunk <span class="token operator">=</span> sentence
    
    <span class="token comment"># Add the last chunk if it's not empty</span>
    <span class="token keyword">if</span> current_chunk<span class="token punctuation">:</span>
        chunks<span class="token punctuation">.</span>append<span class="token punctuation">(</span>current_chunk<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> chunks</code></pre>
</div>
</div>

<h2 id="semantic-chunking">Semantic Chunking</h2>
<p>
Semantic chunking represents a significant advancement over traditional methods by considering the meaning and context of text segments. Rather than relying solely on structural elements like character counts or sentence boundaries, semantic chunking uses embeddings to identify semantically coherent units.
</p>

<div class="not-prose my-12 border border-faded bg-parchment rounded-sm overflow-hidden">
<div class="flex items-center justify-between px-4 py-2 border-b border-faded bg-[#e6dfd1]">
<span class="font-mono text-xs text-ink">semantic_chunking.py</span>
<div class="flex gap-2">
<span class="text-[10px] font-mono text-graphite uppercase">Python</span>
<button class="text-graphite hover:text-primary transition-colors" onclick="copyCode(this)">
<span class="material-symbols-outlined text-[16px]">content_copy</span>
</button>
</div>
</div>
<div class="p-5 overflow-x-auto">
<pre class="font-code text-[13px] leading-6"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> sentence_transformers <span class="token keyword">import</span> SentenceTransformer
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> pairwise_distances_argmin_min
<span class="token keyword">from</span> typing <span class="token keyword">import</span> List<span class="token punctuation">,</span> Tuple

<span class="token keyword">class</span> <span class="token class-name">SemanticChunker</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model_name<span class="token punctuation">:</span> str <span class="token operator">=</span> <span class="token string">"all-MiniLM-L6-v2"</span><span class="token punctuation">,</span> threshold<span class="token punctuation">:</span> float <span class="token operator">=</span> <span class="token number">0.7</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>model <span class="token operator">=</span> SentenceTransformer<span class="token punctuation">(</span>model_name<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>threshold <span class="token operator">=</span> threshold

    <span class="token keyword">def</span> <span class="token function">chunk</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text<span class="token punctuation">:</span> str<span class="token punctuation">,</span> max_chunk_size<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">512</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>str<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Chunk text based on semantic similarity
        """</span>
        <span class="token comment"># First, split into smaller segments (e.g., sentences)</span>
        sentences <span class="token operator">=</span> self<span class="token punctuation">.</span>_split_into_sentences<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
        
        <span class="token comment"># Generate embeddings for each sentence</span>
        embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>sentences<span class="token punctuation">)</span>
        
        chunks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        current_chunk <span class="token operator">=</span> <span class="token punctuation">[</span>sentences<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
        current_embedding <span class="token operator">=</span> embeddings<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentences<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            similarity <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> <span class="token builtin">abs</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>current_embedding<span class="token punctuation">,</span> embeddings<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> 
                           <span class="token punctuation">(</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>current_embedding<span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>embeddings<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            
            <span class="token comment"># If similarity is below threshold or chunk is getting too large, start a new chunk</span>
            <span class="token keyword">if</span> similarity <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>threshold <span class="token operator">or</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>current_chunk<span class="token punctuation">)</span> <span class="token operator">+</span> sentences<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">></span> max_chunk_size<span class="token punctuation">:</span>
                chunks<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>current_chunk<span class="token punctuation">)</span><span class="token punctuation">)</span>
                current_chunk <span class="token operator">=</span> <span class="token punctuation">[</span>sentences<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span>
                current_embedding <span class="token operator">=</span> embeddings<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                current_chunk<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sentences<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
                <span class="token comment"># Update the average embedding for the current chunk</span>
                current_embedding <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>embeddings<span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>chunks<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token builtin">len</span><span class="token punctuation">(</span>chunks<span class="token punctuation">)</span><span class="token operator">+</span><span class="token builtin">len</span><span class="token punctuation">(</span>current_chunk<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        
        <span class="token comment"># Add the last chunk</span>
        <span class="token keyword">if</span> current_chunk<span class="token punctuation">:</span>
            chunks<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>current_chunk<span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> chunks

    <span class="token keyword">def</span> <span class="token function">_split_into_sentences</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text<span class="token punctuation">:</span> str<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>str<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token comment"># Simple sentence splitting - in practice, use nltk or spacy</span>
        <span class="token keyword">import</span> re
        sentences <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span>r<span class="token string">'(?&lt;!\\)([.!?] | [.!?]$)'</span>, text<span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span>s<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> s <span class="token keyword">in</span> sentences <span class="token keyword">if</span> s<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span></code></pre>
</div>
</div>

<h2 id="recursive-splitting">Recursive Splitting</h2>
<p>
Recursive splitting is a hierarchical approach that divides documents based on various delimiters in order of significance. This method attempts to maintain the document's natural structure by splitting first on the most significant boundaries (like sections or chapters) and then recursively subdividing the resulting chunks.
</p>

<div class="not-prose my-12 border border-faded bg-parchment rounded-sm overflow-hidden">
<div class="flex items-center justify-between px-4 py-2 border-b border-faded bg-[#e6dfd1]">
<span class="font-mono text-xs text-ink">recursive_splitting.py</span>
<div class="flex gap-2">
<span class="text-[10px] font-mono text-graphite uppercase">Python</span>
<button class="text-graphite hover:text-primary transition-colors" onclick="copyCode(this)">
<span class="material-symbols-outlined text-[16px]">content_copy</span>
</button>
</div>
</div>
<div class="p-5 overflow-x-auto">
<pre class="font-code text-[13px] leading-6"><code class="language-python"><span class="token keyword">from</span> typing <span class="token keyword">import</span> List<span class="token punctuation">,</span> Optional
<span class="token keyword">import</span> re

<span class="token keyword">class</span> <span class="token class-name">RecursiveCharacterTextSplitter</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        separators<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>List<span class="token punctuation">[</span>str<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        chunk_size<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span>
        chunk_overlap<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">200</span><span class="token punctuation">,</span>
        length_function<span class="token punctuation">:</span> callable <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Recursive text splitter that splits on a list of separators
        """</span>
        self<span class="token punctuation">.</span>separators <span class="token operator">=</span> separators <span class="token keyword">or</span> <span class="token punctuation">[</span><span class="token string">"\n\n"</span><span class="token punctuation">,</span> <span class="token string">"\n"</span><span class="token punctuation">,</span> <span class="token string">" "</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>chunk_size <span class="token operator">=</span> chunk_size
        self<span class="token punctuation">.</span>chunk_overlap <span class="token operator">=</span> chunk_overlap
        self<span class="token punctuation">.</span>length_function <span class="token operator">=</span> length_function

    <span class="token keyword">def</span> <span class="token function">split_text</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text<span class="token punctuation">:</span> str<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>str<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_split_text<span class="token punctuation">(</span>text<span class="token punctuation">,</span> self<span class="token punctuation">.</span>separators<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_split_text</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text<span class="token punctuation">:</span> str<span class="token punctuation">,</span> separators<span class="token punctuation">:</span> List<span class="token punctuation">[</span>str<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>str<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token comment"># Get the first separator</span>
        separator <span class="token operator">=</span> separators<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        <span class="token comment"># Get the rest of the separators</span>
        new_separators <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>separators<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">:</span>
            new_separators <span class="token operator">=</span> separators<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>

        <span class="token comment"># Split the text using the current separator</span>
        splits <span class="token operator">=</span> self<span class="token punctuation">.</span>_split_by_separator<span class="token punctuation">(</span>text<span class="token punctuation">,</span> separator<span class="token punctuation">)</span>

        <span class="token comment"># If no separators were found, or we're at the last separator, return chunks</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>new_separators<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">and</span> <span class="token builtin">len</span><span class="token punctuation">(</span>splits<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token punctuation">[</span>text<span class="token punctuation">]</span>

        <span class="token comment"># Process each split</span>
        final_chunks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> split <span class="token keyword">in</span> splits<span class="token punctuation">:</span>
            <span class="token comment"># If the split is smaller than the chunk size, add it as is</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>length_function<span class="token punctuation">(</span>split<span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>chunk_size<span class="token punctuation">:</span>
                final_chunks<span class="token punctuation">.</span>append<span class="token punctuation">(</span>split<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token comment"># Otherwise, recursively split with the next separator</span>
                other_info <span class="token operator">=</span> self<span class="token punctuation">.</span>_split_text<span class="token punctuation">(</span>split<span class="token punctuation">,</span> new_separators<span class="token punctuation">)</span>
                final_chunks<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>other_info<span class="token punctuation">)</span>

        <span class="token comment"># Merge small chunks with adjacent chunks to avoid tiny fragments</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_merge_splits<span class="token punctuation">(</span>final_chunks<span class="token punctuation">,</span> separator<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_split_by_separator</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text<span class="token punctuation">:</span> str<span class="token punctuation">,</span> separator<span class="token punctuation">:</span> str<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>str<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> separator <span class="token operator">==</span> <span class="token string">""</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token builtin">list</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> text<span class="token punctuation">.</span>split<span class="token punctuation">(</span>separator<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_merge_splits</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> splits<span class="token punctuation">:</span> List<span class="token punctuation">[</span>str<span class="token punctuation">]</span><span class="token punctuation">,</span> separator<span class="token punctuation">:</span> str<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>str<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token comment"># Implementation of merging small splits with adjacent chunks</span>
        <span class="token comment"># This is a simplified version - in practice, this would be more complex</span>
        <span class="token keyword">return</span> splits</code></pre>
</div>
</div>

<h2 id="context-aware-segmentation">Context-Aware Segmentation</h2>
<p>
Context-aware segmentation takes into account the broader document structure and semantic relationships when determining chunk boundaries. This approach considers elements like headers, tables, code blocks, and other structural components to maintain coherence within chunks.
</p>

<div class="not-prose my-12 border border-faded bg-parchment rounded-sm overflow-hidden">
<div class="flex items-center justify-between px-4 py-2 border-b border-faded bg-[#e6dfd1]">
<span class="font-mono text-xs text-ink">context_aware_segmentation.py</span>
<div class="flex gap-2">
<span class="text-[10px] font-mono text-graphite uppercase">Python</span>
<button class="text-graphite hover:text-primary transition-colors" onclick="copyCode(this)">
<span class="material-symbols-outlined text-[16px]">content_copy</span>
</button>
</div>
</div>
<div class="p-5 overflow-x-auto">
<pre class="font-code text-[13px] leading-6"><code class="language-python"><span class="token keyword">import</span> re
<span class="token keyword">from</span> typing <span class="token keyword">import</span> List<span class="token punctuation">,</span> Dict<span class="token punctuation">,</span> Any

<span class="token keyword">class</span> <span class="token class-name">ContextAwareSegmenter</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> chunk_size<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>chunk_size <span class="token operator">=</span> chunk_size
        <span class="token comment"># Define patterns for different document elements</span>
        self<span class="token punctuation">.</span>patterns <span class="token operator">=</span> <span class="token punctuation">{</span>
            <span class="token string">"header"</span><span class="token punctuation">:</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'^#{1,6}\s+(.*)$'</span><span class="token punctuation">,</span> re<span class="token punctuation">.</span>M<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">"list_item"</span><span class="token punctuation">:</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'^\s*[\*\-\+]\s+(.*)$'</span><span class="token punctuation">,</span> re<span class="token punctuation">.</span>M<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">"table_row"</span><span class="token punctuation">:</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'^\s*\|\s*(.*)\s*\|$'</span><span class="token punctuation">,</span> re<span class="token punctuation">.</span>M<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">"code_block"</span><span class="token punctuation">:</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'```.*?$.*?^```'</span><span class="token punctuation">,</span> re<span class="token punctuation">.</span>M <span class="token operator">|</span> re<span class="token punctuation">.</span>S<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span>

    <span class="token keyword">def</span> <span class="token function">segment</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text<span class="token punctuation">:</span> str<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>Dict<span class="token punctuation">[</span>str<span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Segment text while preserving document structure
        """</span>
        <span class="token comment"># Identify document elements and their positions</span>
        elements <span class="token operator">=</span> self<span class="token punctuation">.</span>_identify_elements<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
        
        <span class="token comment"># Create chunks that respect element boundaries</span>
        chunks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        current_chunk <span class="token operator">=</span> <span class="token string">""</span>
        current_start <span class="token operator">=</span> <span class="token number">0</span>
        
        <span class="token keyword">for</span> element <span class="token keyword">in</span> elements<span class="token punctuation">:</span>
            element_text <span class="token operator">=</span> element<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span>
            
            <span class="token comment"># Check if adding this element would exceed the chunk size</span>
            <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>current_chunk<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token builtin">len</span><span class="token punctuation">(</span>element_text<span class="token punctuation">)</span> <span class="token operator">&lt;=</span> self<span class="token punctuation">.</span>chunk_size<span class="token punctuation">:</span>
                current_chunk <span class="token operator">+=</span> element_text
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token comment"># If current chunk is not empty, save it and start a new one</span>
                <span class="token keyword">if</span> current_chunk<span class="token punctuation">:</span>
                    chunks<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span>
                        <span class="token string">"text"</span><span class="token punctuation">:</span> current_chunk<span class="token punctuation">,</span>
                        <span class="token string">"start"</span><span class="token punctuation">:</span> current_start<span class="token punctuation">,</span>
                        <span class="token string">"end"</span><span class="token punctuation">:</span> current_start <span class="token operator">+</span> <span class="token builtin">len</span><span class="token punctuation">(</span>current_chunk<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token string">"elements"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># Track contained elements</span>
                    <span class="token punctuation">}</span><span class="token punctuation">)</span>
                
                <span class="token comment"># Start a new chunk with the current element</span>
                current_chunk <span class="token operator">=</span> element_text
                current_start <span class="token operator">=</span> element<span class="token punctuation">[</span><span class="token string">"start"</span><span class="token punctuation">]</span>
        
        <span class="token comment"># Add the last chunk if it's not empty</span>
        <span class="token keyword">if</span> current_chunk<span class="token punctuation">:</span>
            chunks<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span>
                <span class="token string">"text"</span><span class="token punctuation">:</span> current_chunk<span class="token punctuation">,</span>
                <span class="token string">"start"</span><span class="token punctuation">:</span> current_start<span class="token punctuation">,</span>
                <span class="token string">"end"</span><span class="token punctuation">:</span> current_start <span class="token operator">+</span> <span class="token builtin">len</span><span class="token punctuation">(</span>current_chunk<span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token string">"elements"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token punctuation">}</span><span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> chunks

    <span class="token keyword">def</span> <span class="token function">_identify_elements</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text<span class="token punctuation">:</span> str<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>Dict<span class="token punctuation">[</span>str<span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token comment"># Find all document elements and their positions</span>
        elements <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        
        <span class="token keyword">for</span> pattern_name<span class="token punctuation">,</span> pattern <span class="token keyword">in</span> self<span class="token punctuation">.</span>patterns<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> match <span class="token keyword">in</span> pattern<span class="token punctuation">.</span>finditer<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
                elements<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span>
                    <span class="token string">"type"</span><span class="token punctuation">:</span> pattern_name<span class="token punctuation">,</span>
                    <span class="token string">"text"</span><span class="token punctuation">:</span> match<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    <span class="token string">"start"</span><span class="token punctuation">:</span> match<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    <span class="token string">"end"</span><span class="token punctuation">:</span> match<span class="token punctuation">.</span>end<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token punctuation">}</span><span class="token punctuation">)</span>
        
        <span class="token comment"># Sort elements by position in the text</span>
        elements<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token string">"start"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> elements</code></pre>
</div>
</div>

<h2 id="evaluation">Evaluation of Chunking Strategies</h2>
<p>
Evaluating chunking strategies requires considering multiple factors:
</p>
<ul class="list-disc pl-6 my-6">
<li><strong>Retrieval Quality</strong>: How well do chunks enable relevant information retrieval?</li>
<li><strong>Context Preservation</strong>: Do chunks maintain necessary context for downstream tasks?</li>
<li><strong>Computational Efficiency</strong>: What are the processing and storage costs?</li>
<li><strong>Downstream Task Performance</strong>: How do different strategies affect the final application?</li>
</ul>

</div>
<!-- Footer / Pagination -->
<div class="mt-24 pt-10 border-t border-faded flex justify-between items-center group/footer">
<a class="flex flex-col items-start gap-2 hover:bg-parchment/50 p-4 -ml-4 rounded transition-colors w-1/2" href="module_01_reranking.html">
<span class="font-mono text-xs text-graphite uppercase tracking-wider">Previous Module</span>
<span class="font-display text-lg font-medium text-ink flex items-center gap-2">
<span class="material-symbols-outlined text-[18px]">arrow_back</span>
                            Reranking Strategies
                        </span>
</a>
<div class="h-12 w-px bg-faded mx-4"></div>
<a class="flex flex-col items-end gap-2 hover:bg-parchment/50 p-4 -mr-4 rounded transition-colors w-1/2" href="module_03_embedding_models.html">
<span class="font-mono text-xs text-graphite uppercase tracking-wider">Next Module</span>
<span class="font-display text-lg font-medium text-ink flex items-center gap-2">
                            Embedding Models
                            <span class="material-symbols-outlined text-[18px]">arrow_forward</span>
</span>
</a>
</div>
</article>
<!-- Right Rail: Marginalia -->
<aside class="hidden xl:block w-[240px] sticky top-14 h-[calc(100vh-3.5rem)] pt-32 pb-10 pr-10 pl-4 overflow-y-auto">
<div class="flex flex-col gap-24 relative">
<!-- Note 1: Aligned with introduction -->
<div class="relative group cursor-pointer transition-transform hover:-translate-x-1">
<div class="absolute -left-3 top-1 text-[10px] font-bold text-primary font-mono">[1]</div>
<p class="font-mono text-[12px] leading-5 text-graphite group-hover:text-ink transition-colors">
<strong class="text-ink">Chunking granularity</strong> affects both retrieval accuracy and computational efficiency.
                        </p>
</div>
<!-- Note 2: Aligned with semantic chunking -->
<div class="relative group cursor-pointer transition-transform hover:-translate-x-1 mt-12">
<div class="absolute -left-3 top-1 text-[10px] font-bold text-primary font-mono">[2]</div>
<p class="font-mono text-[12px] leading-5 text-graphite group-hover:text-ink transition-colors">
<strong class="text-ink">Semantic chunking</strong> preserves meaning better than structural approaches.
                        </p>
<a class="inline-flex items-center gap-1 mt-2 text-[10px] uppercase tracking-widest text-primary font-bold hover:underline" href="artifact_view.html" target="_blank">
                            View Code <span class="material-symbols-outlined text-[10px]">open_in_new</span>
</a>
</div>
<!-- Note 3: Aligned with recursive splitting -->
<div class="relative group cursor-pointer transition-transform hover:-translate-x-1 mt-24">
<div class="absolute -left-3 top-1 text-[10px] font-bold text-primary font-mono">[3]</div>
<p class="font-mono text-[12px] leading-5 text-graphite group-hover:text-ink transition-colors">
                            <code class="bg-parchment px-0.5 rounded-sm">Recursive splitting</code> maintains document hierarchy while enabling flexible chunking.
                        </p>
</div>
<!-- Additional marginalia for module-specific content -->
<div class="relative group cursor-pointer transition-transform hover:-translate-x-1 mt-16">
<div class="absolute -left-3 top-1 text-[10px] font-bold text-primary font-mono">[4]</div>
<p class="font-mono text-[12px] leading-5 text-graphite group-hover:text-ink transition-colors">
                            <strong class="text-ink">Context preservation</strong> is crucial for maintaining coherence in downstream tasks.
                        </p>
</div>
<div class="relative group cursor-pointer transition-transform hover:-translate-x-1 mt-16">
<div class="absolute -left-3 top-1 text-[10px] font-bold text-primary font-mono">[5]</div>
<p class="font-mono text-[12px] leading-5 text-graphite group-hover:text-ink transition-colors">
                            <strong class="text-ink">Evaluation metrics</strong> should consider both retrieval quality and downstream task performance.
                        </p>
</div>
</div>
</aside>
</div>
</main>

<script>
    // Function to copy code to clipboard
    function copyCode(button) {
        const codeBlock = button.closest('.not-prose').querySelector('pre code');
        navigator.clipboard.writeText(codeBlock.textContent.trim()).then(() => {
            const originalIcon = button.querySelector('.material-symbols-outlined').textContent;
            button.querySelector('.material-symbols-outlined').textContent = 'check';
            setTimeout(() => {
                button.querySelector('.material-symbols-outlined').textContent = originalIcon;
            }, 2000);
        });
    }

    // Calculate reading time based on content
    document.addEventListener('DOMContentLoaded', function() {
        const content = document.querySelector('.prose-academic').textContent;
        const wordsPerMinute = 200; // Average reading speed
        const wordCount = content.split(/\s+/).length;
        const readingTime = Math.ceil(wordCount / wordsPerMinute);
        
        document.getElementById('reading-time').textContent = `${readingTime} min read`;
    });

    // Search button functionality
    document.getElementById('search-btn').addEventListener('click', function() {
        window.location.href = 'search_index.html';
    });
</script>
</body></html>
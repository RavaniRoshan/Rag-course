<!DOCTYPE html>

<html lang="en"><head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Academic RAG Journal - The Artifact</title>
<!-- Fonts -->
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600;700&amp;family=Inter:wght@400;500;600;700;800&amp;display=swap" rel="stylesheet"/>
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600;700&amp;family=Inter:wght@400;500;600;700;800&amp;display=swap" rel="stylesheet"/>
<!-- Tailwind CSS -->
<script id="tailwind-config">
        tailwind.config = {
            darkMode: "class",
            theme: {
                extend: {
                    colors: {
                        "bg": "#0E0E10",
                        "bg-secondary": "#18181B",
                        "border": "#27272A",
                        "foreground": "#FAFAFA",
                        "muted": "#A1A1AA",
                        "accent": "#3ECF8E",
                        "accent-secondary": "#24A472",
                        "accent-foreground": "#0E0E10",
                        "destructive": "#C92A2A",
                        "warning": "#F59E0B",
                        "info": "#3B82F6",
                    },
                    fontFamily: {
                        "sans": ["Inter", "sans-serif"],
                        "mono": ["JetBrains Mono", "monospace"],
                    },
                    boxShadow: {
                        'brutal': '4px 4px 0px 0px rgba(62, 207, 142, 0.3)',
                        'brutal-lg': '6px 6px 0px 0px rgba(62, 207, 142, 0.4)',
                    },
                    backdropBlur: {
                        'xl': '24px',
                    }
                },
            },
        }
    </script>
<style>
        body {
            font-feature-settings: "cv11", "ss01";
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
        }

        .brutal-border {
            border: 2px solid #27272A;
        }

        .brutal-border-accent {
            border: 2px solid #3ECF8E;
        }

        .brutal-shadow-hover:hover {
            box-shadow: 6px 6px 0px 0px #3ECF8E;
            transform: translate(-2px, -2px);
        }

        .btn-brutal {
            transition: all 0.15s ease-out;
        }

        .btn-brutal:hover {
            transform: translate(-2px, -2px);
            box-shadow: 4px 4px 0px 0px #3ECF8E;
        }

        .btn-brutal:active {
            transform: translate(2px, 2px);
            box-shadow: 0px 0px 0px 0px #3ECF8E;
        }

        .modal-overlay {
            background: rgba(14, 14, 16, 0.8);
            backdrop-filter: blur(4px);
        }

        .modal-content {
            animation: modalSlideIn 0.3s ease-out;
        }

        @keyframes modalSlideIn {
            from {
                opacity: 0;
                transform: translateY(-20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        /* Glassmorphism Navbar */
        .glass-nav {
            background: rgba(14, 14, 16, 0.6);
            backdrop-filter: blur(24px);
            -webkit-backdrop-filter: blur(24px);
            border-bottom: 1px solid rgba(39, 39, 42, 0.5);
        }

        /* Fix overlapping elements */
        .prose h1, .prose h2, .prose h3 {
            margin-top: 1.5em;
            margin-bottom: 0.75em;
            line-height: 1.3;
        }

        .prose p {
            margin-top: 1em;
            margin-bottom: 1em;
            line-height: 1.8;
        }

        .prose pre {
            margin-top: 1.5em;
            margin-bottom: 1.5em;
            overflow-x: auto;
        }

        .prose code {
            word-wrap: break-word;
            white-space: pre-wrap;
        }

        .prose ul, .prose ol {
            margin-top: 0.75em;
            margin-bottom: 0.75em;
            padding-left: 1.5em;
        }

        .prose li {
            margin-top: 0.5em;
            margin-bottom: 0.5em;
        }

        @media (max-width: 768px) {
            .prose h1 { font-size: 1.75rem; }
            .prose h2 { font-size: 1.5rem; }
            .prose p { font-size: 0.95rem; }
        }
    </style>
</head>
<body class="bg-bg text-foreground font-sans">
<!-- Texture Overlay -->
<div class="grain-overlay"></div>
<!-- Header Navigation -->
<header class="flex-none border-b border-border bg-bg-secondary z-40 px-6 py-4 flex justify-between items-center h-16">
<div class="flex items-center gap-6">
<a class="group flex items-center gap-2 text-foreground hover:text-accent transition-colors" href="module_04_vector_databases.html">
<span class="material-symbols-outlined text-lg">arrow_back</span>
<span class="font-mono text-xs uppercase tracking-wider font-medium">Return to Article</span>
</a>
<div class="h-4 w-px bg-border"></div>
<h1 class="font-display font-semibold text-xl tracking-tight text-foreground">Module 04: Contextual Reranking Implementation</h1>
</div>
<div class="flex items-center gap-4">
<div class="flex items-center gap-2 px-3 py-1.5 bg-bg rounded border border-border text-xs font-mono text-muted">
<span class="material-symbols-outlined text-sm">code</span>
<span>Python 3.10</span>
</div>
<button class="flex items-center justify-center gap-2 px-4 py-1.5 bg-ink text-paper hover:bg-accent transition-colors rounded text-xs font-mono font-medium tracking-wide">
<span class="material-symbols-outlined text-sm">download</span>
                Download Source
            </button>
</div>
</header>
<!-- Main Split View -->
<main class="flex-1 flex overflow-hidden">
<!-- Left Pane: Narrative Explanation -->
<div class="w-1/2 overflow-y-auto custom-scrollbar border-r border-border bg-bg-secondary p-12 pb-32">
<div class="max-w-xl mx-auto space-y-12">
<div class="space-y-4">
<span class="font-mono text-xs font-medium text-accent uppercase tracking-widest">Part 1: Setup</span>
<h2 class="font-display text-3xl font-bold text-foreground leading-tight">Initialization &amp; Dependencies</h2>
<p class="text-lg leading-relaxed text-foreground/90">
                        The foundation of our reranker relies on the <span class="font-mono text-sm bg-bg px-1 rounded text-accent">CrossEncoder</span> architecture from the Sentence Transformers library. Unlike bi-encoders, which process queries and documents independently, this approach feeds both inputs simultaneously into the transformer model.
                    </p>
<p class="text-lg leading-relaxed text-foreground/90">
                        We begin by importing necessary libraries. Note specifically the usage of <span class="font-mono text-sm bg-bg px-1 rounded text-accent">torch</span> for tensor operations, which allows us to efficiently manage the logits produced during the inference phase.
                    </p>
</div>
<div class="relative group cursor-pointer transition-all duration-300">
<div class="absolute -left-6 top-0 bottom-0 w-1 bg-border group-hover:bg-accent transition-colors"></div>
<div class="space-y-4 pl-4 group-hover:bg-bg/30 -ml-4 rounded-r p-4 transition-colors">
<span class="font-mono text-xs font-medium text-muted uppercase tracking-widest">Part 2: The Class Structure</span>
<h3 class="font-display text-2xl font-semibold text-foreground">Defining the ContextualReranker</h3>
<p class="text-lg leading-relaxed text-foreground/90">
                            Here we define the core class. The constructor accepts a <span class="font-mono text-sm bg-bg px-1 rounded text-accent">model_name</span> string, defaulting to the robust MS Marco distilled model.
                        </p>
<p class="text-lg leading-relaxed text-foreground/90">
                            This initialization phase is critical. We force the device to CUDA if available, ensuring that the heavy lifting of cross-attention calculation doesn't bottleneck the retrieval pipeline on the CPU.
                        </p>
</div>
</div>
<div class="space-y-4 opacity-60 hover:opacity-100 transition-opacity duration-300">
<span class="font-mono text-xs font-medium text-muted uppercase tracking-widest">Part 3: Inference Logic</span>
<h3 class="font-display text-2xl font-semibold text-foreground">The Rank Method</h3>
<p class="text-lg leading-relaxed text-foreground/90">
                        The <span class="font-mono text-sm bg-bg px-1 rounded text-accent">rank()</span> method is where the magic happens. It takes a query and a list of candidate documents.
                    </p>
<p class="text-lg leading-relaxed text-foreground/90">
                        It first pairs the query with each document, creating a list of tuples. The model then predicts scores for these pairs. Finally, we sort the original documents based on these new semantic scores in descending order, effectively bubbling the most relevant context to the top.
                    </p>
</div>
<div class="p-6 bg-bg/50 border border-border rounded">
<div class="flex items-start gap-3">
<span class="material-symbols-outlined text-accent mt-0.5">info</span>
<div class="space-y-2">
<h4 class="font-display font-bold text-foreground">Performance Note</h4>
<p class="text-sm font-body text-foreground/80 leading-relaxed">
                                While accurate, cross-encoders are computationally expensive. In production, this <span class="font-mono text-xs">rank()</span> method should only be applied to the top 50-100 results from a faster initial retrieval step (like BM25 or a vector search).
                            </p>
</div>
</div>
</div>
</div>
</div>
<!-- Right Pane: Code Artifact -->
<div class="w-1/2 flex flex-col bg-bg relative">
<!-- Code Toolbar -->
<div class="flex-none flex items-center justify-between px-6 py-3 border-b border-border bg-bg/90 backdrop-blur sticky top-0 z-10">
<span class="font-mono text-sm text-foreground font-bold">reranker_pipeline.py</span>
<div class="flex gap-3">
<button class="text-muted hover:text-foreground transition-colors p-1" title="Copy Code" onclick="copyCode()">
<span class="material-symbols-outlined text-lg">content_copy</span>
</button>
<button class="text-muted hover:text-foreground transition-colors p-1" title="Toggle Wrap">
<span class="material-symbols-outlined text-lg">wrap_text</span>
</button>
</div>
</div>
<!-- Code Content -->
<div class="flex-1 overflow-y-auto custom-scrollbar p-8 pl-12 font-code text-sm leading-7">
<pre class="relative"><code class="language-python block">
<span class="code-line"><span class="token comment"># Standard library imports</span></span>
<span class="code-line"><span class="token keyword">from</span> typing <span class="token keyword">import</span> List, Tuple, Dict, Any</span>
<span class="code-line"><span class="token keyword">import</span> time</span>
<span class="code-line"></span>
<span class="code-line"><span class="token comment"># Third-party imports for tensor operations and modeling</span></span>
<span class="code-line"><span class="token keyword">import</span> torch</span>
<span class="code-line"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np</span>
<span class="code-line"><span class="token keyword">from</span> sentence_transformers <span class="token keyword">import</span> CrossEncoder</span>
<span class="code-line"></span>
<span class="code-line"><span class="token comment"># -----------------------------------------------------------------------------</span></span>
<span class="code-line"><span class="token comment"># Configuration Constants</span></span>
<span class="code-line"><span class="token comment"># -----------------------------------------------------------------------------</span></span>
<span class="code-line"><span class="token class-name">DEFAULT_MODEL</span> <span class="token operator">=</span> <span class="token string">"cross-encoder/ms-marco-MiniLM-L-6-v2"</span></span>
<span class="code-line"><span class="token class-name">MAX_LENGTH</span> <span class="token operator">=</span> <span class="token number">512</span></span>
<span class="code-line"></span>
<span class="code-line"><span class="token comment"># Active Highlight Area Start (Matches Part 2 in Left Pane)</span></span>
<div class="absolute left-[-2rem] right-[-2rem] bg-border/40 border-l-4 border-accent pointer-events-none mix-blend-multiply" style="top: 390px; height: 310px;"></div>
<span class="code-line"><span class="token keyword">class</span> <span class="token class-name">ContextualReranker</span>:</span>
<span class="code-line">    <span class="token string">"""</span></span>
<span class="code-line"><span class="token string">    A wrapper class for Cross-Encoder models to re-rank retrieved documents</span></span>
<span class="code-line"><span class="token string">    based on their relevance to a specific query.</span></span>
<span class="code-line"><span class="token string">    """</span></span>
<span class="code-line">    </span>
<span class="code-line">    <span class="token keyword">def</span> <span class="token function">__init__</span>(self, model_name: str = <span class="token class-name">DEFAULT_MODEL</span>, device: str = <span class="token keyword">None</span>):</span>
<span class="code-line">        <span class="token string">"""</span></span>
<span class="code-line"><span class="token string">        Initialize the CrossEncoder model.</span></span>
<span class="code-line"><span class="token string">        </span></span>
<span class="code-line"><span class="token string">        Args:</span></span>
<span class="code-line"><span class="token string">            model_name (str): HuggingFace model identifier.</span></span>
<span class="code-line"><span class="token string">            device (str): Computation device ('cuda' or 'cpu'). Auto-detected if None.</span></span>
<span class="code-line"><span class="token string">        """</span></span>
<span class="code-line">        <span class="token keyword">if</span> device <span class="token keyword">is</span> <span class="token keyword">None</span>:</span>
<span class="code-line">            self.device <span class="token operator">=</span> <span class="token string">"cuda"</span> <span class="token keyword">if</span> torch.cuda.is_available() <span class="token keyword">else</span> <span class="token string">"cpu"</span></span>
<span class="code-line">        <span class="token keyword">else</span>:</span>
<span class="code-line">            self.device <span class="token operator">=</span> device</span>
<span class="code-line">            </span>
<span class="code-line">        <span class="token keyword">print</span>(<span class="token string">f"Loading Reranker on {self.device}..."</span>)</span>
<span class="code-line">        self.model <span class="token operator">=</span> <span class="token class-name">CrossEncoder</span>(</span>
<span class="code-line">            model_name, </span>
<span class="code-line">            max_length=<span class="token class-name">MAX_LENGTH</span>, </span>
<span class="code-line">            device=self.device</span>
<span class="code-line">        )</span>
<span class="code-line"><span class="token comment"># Active Highlight Area End</span></span>
<span class="code-line"></span>
<span class="code-line">    <span class="token keyword">def</span> <span class="token function">rank</span>(self, query: str, docs: List[str], top_k: int = <span class="token keyword">None</span>) -&gt; List[Dict[str, Any]]:</span>
<span class="code-line">        <span class="token string">"""</span></span>
<span class="code-line"><span class="token string">        Re-ranks a list of documents based on the query.</span></span>
<span class="code-line"><span class="token string">        """</span></span>
<span class="code-line">        <span class="token keyword">if</span> <span class="token keyword">not</span> docs:</span>
<span class="code-line">            <span class="token keyword">return</span> []</span>
<span class="code-line">            </span>
<span class="code-line">        <span class="token comment"># Prepare pairs for the CrossEncoder: [[query, doc1], [query, doc2], ...]</span></span>
<span class="code-line">        model_inputs <span class="token operator">=</span> [[query, doc] <span class="token keyword">for</span> doc <span class="token keyword">in</span> docs]</span>
<span class="code-line">        </span>
<span class="code-line">        <span class="token comment"># Predict scores</span></span>
<span class="code-line">        scores <span class="token operator">=</span> self.model.predict(model_inputs)</span>
<span class="code-line">        </span>
<span class="code-line">        <span class="token comment"># Combine docs with scores</span></span>
<span class="code-line">        results <span class="token operator">=</span> []</span>
<span class="code-line">        <span class="token keyword">for</span> i, doc <span class="token keyword">in</span> enumerate(docs):</span>
<span class="code-line">            results.append({</span>
<span class="code-line">                <span class="token string">"text"</span>: doc,</span>
<span class="code-line">                <span class="token string">"score"</span>: float(scores[i]),</span>
<span class="code-line">                <span class="token string">"original_index"</span>: i</span>
<span class="code-line">            })</span>
<span class="code-line">            </span>
<span class="code-line">        <span class="token comment"># Sort by score descending</span></span>
<span class="code-line">        results <span class="token operator">=</span> sorted(results, key=<span class="token keyword">lambda</span> x: x[<span class="token string">"score"</span>], reverse=<span class="token keyword">True</span>)</span>
<span class="code-line">        </span>
<span class="code-line">        <span class="token keyword">if</span> top_k:</span>
<span class="code-line">            results <span class="token operator">=</span> results[:top_k]</span>
<span class="code-line">            </span>
<span class="code-line">        <span class="token keyword">return</span> results</span>
<span class="code-line"></span>
<span class="code-line"><span class="token comment"># -----------------------------------------------------------------------------</span></span>
<span class="code-line"><span class="token comment"># Usage Example</span></span>
<span class="code-line"><span class="token comment"># -----------------------------------------------------------------------------</span></span>
<span class="code-line"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span>:</span>
<span class="code-line">    reranker <span class="token operator">=</span> <span class="token class-name">ContextualReranker</span>()</span>
<span class="code-line">    q <span class="token operator">=</span> <span class="token string">"What is the capital of France?"</span></span>
<span class="code-line">    candidates <span class="token operator">=</span> [</span>
<span class="code-line">        <span class="token string">"Berlin is the capital of Germany."</span>,</span>
<span class="code-line">        <span class="token string">"Paris is the capital of France."</span>,</span>
<span class="code-line">        <span class="token string">"Lyon is a major city in France."</span></span>
<span class="code-line">    ]</span>
<span class="code-line">    ranked_docs <span class="token operator">=</span> reranker.rank(q, candidates)</span>
<span class="code-line">    <span class="token keyword">print</span>(ranked_docs)</span>
</code></pre>
</div>
<!-- Bottom Fade for infinite scroll feel -->
<div class="absolute bottom-0 left-0 right-0 h-16 bg-gradient-to-t from-parchment to-transparent pointer-events-none"></div>
</div>
</main>

<script>
    function copyCode() {
        const codeElement = document.querySelector('pre code');
        const text = codeElement.innerText;
        
        navigator.clipboard.writeText(text).then(() => {
            // Show temporary success indicator
            const copyButton = document.querySelector('[title="Copy Code"]');
            const originalIcon = copyButton.innerHTML;
            copyButton.innerHTML = '<span class="material-symbols-outlined text-lg">check</span>';
            
            setTimeout(() => {
                copyButton.innerHTML = originalIcon;
            }, 2000);
        }).catch(err => {
            console.error('Failed to copy code: ', err);
        });
    }
</script>
</body></html>